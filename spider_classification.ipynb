{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4xvr1q3Wxr6S"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.io\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBd7Cr0Ugebo",
        "outputId": "08203bee-65cd-4b42-c2d1-2c5678bb8345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "DEVICE = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "print(f\"Using {DEVICE} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whDnxIfgVot5"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "        image = read_image(img_path,ImageReadMode.RGB).float()\n",
        "       \n",
        "        label = self.img_labels.iloc[idx, 4]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test):\n",
        "        self.batch_size = batch_size\n",
        "        self.training_data = dataset_train\n",
        "        self.test_data = dataset_test\n",
        "    \n",
        "    def get_loader(self, training: bool):\n",
        "        if training:\n",
        "            dataloader = DataLoader(self.training_data,batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            dataloader = DataLoader(self.test_data,batch_size=self.batch_size, shuffle=False)\n",
        "        return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DEvb04PxuFa"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test):\n",
        "        self.batch_size = batch_size\n",
        "        self.training_data = dataset_train\n",
        "        self.test_data = dataset_test\n",
        "    \n",
        "    def get_loader(self, training: bool):\n",
        "        if training:\n",
        "            dataloader = DataLoader(self.training_data,batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            dataloader = DataLoader(self.test_data,batch_size=self.batch_size, shuffle=False)\n",
        "        return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlfyjbXSxv5a"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, kernel_size=7, stride=1, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12 * 112*112, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,15)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIluUow5xxnR"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self):\n",
        "        self.model = NeuralNetwork()\n",
        "        self.model.to(DEVICE)\n",
        "        self.optimizer =  torch.optim.SGD(self.model.parameters(), lr=0.5e-7)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def update(self, loss):\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qU2IwGAxzQ0"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self):\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "            \n",
        "    def get_loss(self, y, y_hat):\n",
        "        return self.loss_fn(y_hat,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbj-aWkIx1v4"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator):\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "        self.evaluator = evaluator\n",
        "        self.writer = SummaryWriter()\n",
        "    def one_epoch(self, training: bool):\n",
        "        self.learner.model.train(training)\n",
        "        dataloader = self.data.get_loader(training)\n",
        "        test_loss,train_loss, correct = 0, 0, 0\n",
        "        predictions = []\n",
        "        labels = []\n",
        "        num_batches = len(dataloader)\n",
        "        size = len(dataloader.dataset)\n",
        "        for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = self.learner.predict(X)\n",
        "            loss = self.evaluator.get_loss(y, y_hat)\n",
        "            if training:\n",
        "                self.learner.update(loss)\n",
        "                train_loss+=loss.item()\n",
        "                if batch_idx % 500 == 0:\n",
        "                    loss, current = loss.item(), (batch_idx + 1) * len(X)\n",
        "                    print(loss)\n",
        "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            else:\n",
        "                test_loss += loss.item()\n",
        "                predictions.extend(y_hat.argmax(1).tolist()) \n",
        "                correct += (y_hat.argmax(1) == y).sum().item()\n",
        "                labels.extend(y.tolist())\n",
        "                                \n",
        "        if not training:\n",
        "            test_loss /= num_batches\n",
        "            correct /= size\n",
        "            print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "            accuracy = correct*100\n",
        "            return test_loss, accuracy, predictions,labels\n",
        "        else:\n",
        "            train_loss /= num_batches\n",
        "            return train_loss\n",
        "    \n",
        "    def run(self, n_epochs: int):\n",
        "        for t in range(n_epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            train_loss = self.one_epoch(training=True)\n",
        "            with torch.no_grad():\n",
        "                test_loss,test_acc, preds, labels= self.one_epoch(training=False)               \n",
        "                test_f1 = f1_score(labels,preds, average='macro')*100\n",
        "                \n",
        "                \n",
        "            self.writer.add_scalar('Loss/Train',train_loss, t)\n",
        "            self.writer.add_scalar('Loss/Test',test_loss, t)\n",
        "            self.writer.add_scalar('Loss/Test-acc',test_acc, t)\n",
        "            self.writer.add_scalar('Loss/Test-f1',test_f1, t)\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ex4GNM-ilTe"
      },
      "outputs": [],
      "source": [
        "train = 'train'\n",
        "test = 'test'\n",
        "path_train = f'dataset/spiders_{train}.csv'\n",
        "path_test = f'dataset/spiders_{test}.csv'\n",
        "base_dir = 'dataset'\n",
        "dataset_train = CustomImageDataset(path_train,base_dir)\n",
        "dataset_test = CustomImageDataset(path_test,base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4BXAnSxiVN6"
      },
      "outputs": [],
      "source": [
        "data = Data(8, dataset_train,dataset_test)\n",
        "learner = Learner()\n",
        "evaluator = Evaluator()\n",
        "trainer = Trainer(data, learner, evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eiXXSLCcjv2_",
        "outputId": "feb3b464-0cc0-4270-fb4d-e069186cb20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "5.9513373374938965\n",
            "loss: 5.951337  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 6.7%, Avg loss: 3.556385 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "3.8347630500793457\n",
            "loss: 3.834763  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 8.0%, Avg loss: 3.356377 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "3.5299854278564453\n",
            "loss: 3.529985  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 9.3%, Avg loss: 3.254321 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "2.7150661945343018\n",
            "loss: 2.715066  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 10.7%, Avg loss: 3.168898 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "3.061831474304199\n",
            "loss: 3.061831  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 13.3%, Avg loss: 3.099232 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "2.452343702316284\n",
            "loss: 2.452344  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 12.0%, Avg loss: 3.047474 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "2.7932071685791016\n",
            "loss: 2.793207  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 13.3%, Avg loss: 2.982617 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "2.859605073928833\n",
            "loss: 2.859605  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 13.3%, Avg loss: 2.930615 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "2.9196765422821045\n",
            "loss: 2.919677  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 12.0%, Avg loss: 2.889904 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "3.459226131439209\n",
            "loss: 3.459226  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 14.7%, Avg loss: 2.836495 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "3.143340826034546\n",
            "loss: 3.143341  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 13.3%, Avg loss: 2.798987 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "3.037510633468628\n",
            "loss: 3.037511  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 16.0%, Avg loss: 2.765225 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "2.774014472961426\n",
            "loss: 2.774014  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 14.7%, Avg loss: 2.731862 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "2.837283134460449\n",
            "loss: 2.837283  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 14.7%, Avg loss: 2.697135 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "3.4356837272644043\n",
            "loss: 3.435684  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 16.0%, Avg loss: 2.680425 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "2.4831275939941406\n",
            "loss: 2.483128  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 17.3%, Avg loss: 2.641704 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "2.1903438568115234\n",
            "loss: 2.190344  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 17.3%, Avg loss: 2.625878 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "2.1956145763397217\n",
            "loss: 2.195615  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 17.3%, Avg loss: 2.592745 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "2.1283695697784424\n",
            "loss: 2.128370  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 18.7%, Avg loss: 2.598649 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "2.1597647666931152\n",
            "loss: 2.159765  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 17.3%, Avg loss: 2.560896 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "2.4794270992279053\n",
            "loss: 2.479427  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.544810 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "2.3632731437683105\n",
            "loss: 2.363273  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.520855 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "2.320584297180176\n",
            "loss: 2.320584  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.505805 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "3.2749667167663574\n",
            "loss: 3.274967  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 18.7%, Avg loss: 2.501032 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "1.6498256921768188\n",
            "loss: 1.649826  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.474914 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "2.640984058380127\n",
            "loss: 2.640984  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.464997 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "2.4046196937561035\n",
            "loss: 2.404620  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.458002 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "2.4264650344848633\n",
            "loss: 2.426465  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.445416 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "2.7344233989715576\n",
            "loss: 2.734423  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.428803 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "2.685971736907959\n",
            "loss: 2.685972  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.420407 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "1.9196983575820923\n",
            "loss: 1.919698  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.402223 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "2.2397568225860596\n",
            "loss: 2.239757  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.399358 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "2.118455648422241\n",
            "loss: 2.118456  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.377478 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "3.0140633583068848\n",
            "loss: 3.014063  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.375983 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "2.8379945755004883\n",
            "loss: 2.837995  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 20.0%, Avg loss: 2.358953 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "2.5983431339263916\n",
            "loss: 2.598343  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.356180 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "2.405381679534912\n",
            "loss: 2.405382  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.346747 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "1.6907471418380737\n",
            "loss: 1.690747  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.329067 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "3.006526470184326\n",
            "loss: 3.006526  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.327542 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "2.239678144454956\n",
            "loss: 2.239678  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.310980 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "2.091994285583496\n",
            "loss: 2.091994  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.309406 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "1.6603974103927612\n",
            "loss: 1.660397  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.288818 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "2.248737335205078\n",
            "loss: 2.248737  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.287289 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "1.8391375541687012\n",
            "loss: 1.839138  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.274503 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "2.0592269897460938\n",
            "loss: 2.059227  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.272794 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "2.4539763927459717\n",
            "loss: 2.453976  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.260659 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "1.9404823780059814\n",
            "loss: 1.940482  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.256144 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "2.121344804763794\n",
            "loss: 2.121345  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.251163 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "1.6201282739639282\n",
            "loss: 1.620128  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 2.255555 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "1.9627525806427002\n",
            "loss: 1.962753  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 22.7%, Avg loss: 2.244179 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "2.2311630249023438\n",
            "loss: 2.231163  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.225043 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "2.382458448410034\n",
            "loss: 2.382458  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.219706 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "2.4782297611236572\n",
            "loss: 2.478230  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.210535 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "2.4820027351379395\n",
            "loss: 2.482003  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.201593 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "2.456794500350952\n",
            "loss: 2.456795  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.202963 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "2.185711145401001\n",
            "loss: 2.185711  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.204238 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "1.6204512119293213\n",
            "loss: 1.620451  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.191202 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "2.0489087104797363\n",
            "loss: 2.048909  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.186248 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "2.2229232788085938\n",
            "loss: 2.222923  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.181340 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "2.2227160930633545\n",
            "loss: 2.222716  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.174884 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "1.8387898206710815\n",
            "loss: 1.838790  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.166613 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "1.8695608377456665\n",
            "loss: 1.869561  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.161626 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "1.9109774827957153\n",
            "loss: 1.910977  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.155152 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "2.5326483249664307\n",
            "loss: 2.532648  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.152386 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "2.3142035007476807\n",
            "loss: 2.314204  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.153877 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "1.8078110218048096\n",
            "loss: 1.807811  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.145221 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "2.1598098278045654\n",
            "loss: 2.159810  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.147010 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "1.9028247594833374\n",
            "loss: 1.902825  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.138795 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "1.337525725364685\n",
            "loss: 1.337526  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.131136 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "2.0785179138183594\n",
            "loss: 2.078518  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 26.7%, Avg loss: 2.122361 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "1.277536392211914\n",
            "loss: 1.277536  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.120669 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "1.6119928359985352\n",
            "loss: 1.611993  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.116209 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "1.6443865299224854\n",
            "loss: 1.644387  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.112773 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "1.6171656847000122\n",
            "loss: 1.617166  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.115973 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "1.779839038848877\n",
            "loss: 1.779839  [    8/ 2185]\n",
            "Test Error: \n",
            " Accuracy: 25.3%, Avg loss: 2.103739 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "trainer.run(100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
