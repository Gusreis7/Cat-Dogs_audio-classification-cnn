{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oTMoL4w-f6jk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gustavo/anaconda3/envs/rnp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/gustavo/anaconda3/envs/rnp/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.0)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch import nn\n",
        "import wandb\n",
        "from PIL import Image\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torchaudio\n",
        "import librosa\n",
        "from torchaudio import transforms\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgustavoreis\u001b[0m (\u001b[33mtropadochatgpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1cYFSNIEQV",
        "outputId": "21ed2c0b-0246-4454-95f1-1022c2f949ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "DEVICE = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "NUM_WORKERS = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rE01DalYnP_a"
      },
      "outputs": [],
      "source": [
        "def get_db_spectogram(waveform):\n",
        "    transform = torchaudio.transforms.Spectrogram(n_fft=600)\n",
        "    spectrogram = transform(waveform)\n",
        "    spectrogram = transforms.AmplitudeToDB()(spectrogram)\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "def audio_padding(waveform,sr, max_s):\n",
        "    max_len = max_s*sr\n",
        "    n_rows, wav_len = waveform.shape\n",
        "    if (wav_len/sr) > max_s:\n",
        "        waveform = waveform[:,:max_len] # trucating\n",
        "    else:\n",
        "        #complete the edges of audio with zeros\n",
        "        pad_begin = random.randint(0,(max_len - wav_len))\n",
        "        pad_end = max_len -wav_len- pad_begin\n",
        "        begin_zeros = torch.zeros(n_rows,pad_begin)\n",
        "        end_zeros = torch.zeros(n_rows,pad_end)\n",
        "        waveform = torch.cat((begin_zeros, waveform,end_zeros),1)\n",
        "    \n",
        "    return waveform\n",
        "\n",
        "\n",
        "class CustomAudioDataset(Dataset):\n",
        "    def __init__(self, annotations_file,path_idx,label_idx, base_dir,target_sample_rate ,transform=None, target_transform=None, labe2id = None):\n",
        "        self.files = pd.read_csv(annotations_file)\n",
        "        self.path_idx = path_idx\n",
        "        self.label_idx = label_idx\n",
        "        self.base_dir = base_dir\n",
        "        self.sample_rate = target_sample_rate\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.label2id = {'cat':0,'dog':1}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = os.path.join(self.base_dir, self.files.iloc[idx, self.path_idx])\n",
        "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
        "        if sample_rate != self.sample_rate:\n",
        "            transform = transforms.Resample(sample_rate, self.sample_rate)\n",
        "            waveform = transform(waveform)\n",
        "        waveform = torch.cat([waveform,waveform])\n",
        "        waveform = audio_padding(waveform,sample_rate,5)\n",
        "        spec = get_db_spectogram(waveform)\n",
        "        label = self.files.iloc[idx, self.label_idx]\n",
        "        label = self.label2id[label]\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return spec, label\n",
        "    \n",
        "class Data:\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test):\n",
        "        self.batch_size = batch_size\n",
        "        self.training_data = dataset_train\n",
        "        self.test_data = dataset_test\n",
        "    \n",
        "    def get_loader(self, training: bool):\n",
        "        if training:\n",
        "            dataloader = DataLoader(self.training_data,batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            dataloader = DataLoader(self.test_data,batch_size=self.batch_size, shuffle=False)\n",
        "        return dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "As9ktj9wogCW"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self):\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_loss(self, y, y_hat):\n",
        "        return self.loss_fn(y_hat, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(2,4, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(4,2, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2*76*67,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = self.conv_layer(x)\n",
        "        #print(x.shape)\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "   \n",
        "    \n",
        "class Learner:\n",
        "    def __init__(self):\n",
        "        self.model = NeuralNetwork()\n",
        "        self.model.to(DEVICE)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=2e-6)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def update(self, loss):\n",
        "        # Backpropagation\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y0vHOBrxpBZS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator):\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "    def one_epoch(self, training: bool):\n",
        "        self.learner.model.train(training)\n",
        "        dataloader = self.data.get_loader(training)\n",
        "        test_loss, correct = 0, 0\n",
        "        train_loss = 0\n",
        "        num_batches = len(dataloader)\n",
        "        size = len(dataloader.dataset)\n",
        "        for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = self.learner.predict(X)\n",
        "            #print(X.shape)\n",
        "            loss = self.evaluator.get_loss(y, y_hat)\n",
        "            if training:\n",
        "                self.learner.update(loss)\n",
        "                train_loss += loss.item()\n",
        "                if batch_idx % 100 == 0:\n",
        "                    loss, current = loss.item(), (batch_idx + 1) * len(X)\n",
        "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "                \n",
        "            else:\n",
        "                test_loss += loss.item()\n",
        "                correct += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "        if not training:\n",
        "            test_loss /= num_batches\n",
        "            correct /= size\n",
        "            test_acc = 100*correct\n",
        "            print(f\"Test Error: \\n Accuracy: {test_acc:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "            return test_loss, test_acc\n",
        "        else:\n",
        "            print(\"aaaaaaaaaa\")\n",
        "            print(train_loss)\n",
        "            print(num_batches)\n",
        "            train_loss /= num_batches\n",
        "            return train_loss\n",
        "\n",
        "    def run(self, n_epochs: int):\n",
        "        wandb.init(project=\"CatXDogs\", entity=\"gustavoreis\")\n",
        "        for t in range(n_epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            #start = time.time()\n",
        "            train_loss = self.one_epoch(training=True)\n",
        "            #end = time.time()\n",
        "            #print(f\"time: {end - start:.2f}s\")\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_acc = self.one_epoch(training=False)\n",
        "            wandb.log({\"Loss/train per epoch\": train_loss, \"Loss/test per epoch\": test_loss, \"Accuracy/test\": test_acc})\n",
        "        print(\"Done!\")\n",
        "        wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JbPFwuwbFbue"
      },
      "outputs": [],
      "source": [
        "dataset_train = CustomAudioDataset('dataset/train.csv',base_dir ='',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "dataset_test = CustomAudioDataset('dataset/test.csv',base_dir = '',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "data = Data(2, dataset_train,dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6cDEEBI8GHRR"
      },
      "outputs": [],
      "source": [
        "learner = Learner()\n",
        "evaluator = Evaluator()\n",
        "trainer = Trainer(data, learner, evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YljWIIb2Gea6",
        "outputId": "f1bb324b-ba21-4372-a4a7-31f8d615aa61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgustavoreis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gustavo/PersonalProjects/Cat-Dogs_audio-classification/wandb/run-20230720_215958-oma0b2qe</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gustavoreis/CatXDogs/runs/oma0b2qe' target=\"_blank\">magic-night-174</a></strong> to <a href='https://wandb.ai/gustavoreis/CatXDogs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gustavoreis/CatXDogs' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gustavoreis/CatXDogs/runs/oma0b2qe' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs/runs/oma0b2qe</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.528307  [    2/  207]\n",
            "loss: 0.353574  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "70.75565458834171\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 62.9%, Avg loss: 0.641449 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.497007  [    2/  207]\n",
            "loss: 0.536272  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "66.03427036106586\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.523280 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.521091  [    2/  207]\n",
            "loss: 1.059591  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "61.228877395391464\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 48.6%, Avg loss: 0.710255 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.584729  [    2/  207]\n",
            "loss: 0.298428  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "60.143664725124836\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 0.632962 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.515938  [    2/  207]\n",
            "loss: 0.538172  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "60.05936797708273\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.556843 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.246812  [    2/  207]\n",
            "loss: 0.264789  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "57.13040166348219\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.538985 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.215519  [    2/  207]\n",
            "loss: 1.186334  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "54.69189339131117\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.515158 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.583496  [    2/  207]\n",
            "loss: 0.852330  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "51.74960430338979\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.620832 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.930445  [    2/  207]\n",
            "loss: 0.113833  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "52.63332914561033\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.531673 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.138176  [    2/  207]\n",
            "loss: 0.529314  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "53.00316931307316\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.524334 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.571785  [    2/  207]\n",
            "loss: 1.005753  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "50.44563766568899\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.513508 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.216023  [    2/  207]\n",
            "loss: 0.480033  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "51.17862272262573\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.546278 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.584487  [    2/  207]\n",
            "loss: 0.837721  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "45.551812261343\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.560424 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.799837  [    2/  207]\n",
            "loss: 1.326499  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "48.3483329154551\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.630945 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.580554  [    2/  207]\n",
            "loss: 0.453226  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "48.79452037811279\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.515458 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.501930  [    2/  207]\n",
            "loss: 0.637096  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "49.36338821798563\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.472191 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.576315  [    2/  207]\n",
            "loss: 0.220368  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "46.68801578134298\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.487457 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.423891  [    2/  207]\n",
            "loss: 0.122951  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "44.7801131112501\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.713040 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.060010  [    2/  207]\n",
            "loss: 0.392339  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "46.46656350046396\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.462017 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.222913  [    2/  207]\n",
            "loss: 0.620427  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "43.30889355391264\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.466021 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.107734  [    2/  207]\n",
            "loss: 0.053457  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "45.98697749711573\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.435369 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.256179  [    2/  207]\n",
            "loss: 0.899251  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "42.793653678148985\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.451775 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.421436  [    2/  207]\n",
            "loss: 0.168166  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "40.39714444056153\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.491404 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.598607  [    2/  207]\n",
            "loss: 0.476049  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "40.066393092274666\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.445440 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.538807  [    2/  207]\n",
            "loss: 0.334426  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "38.82920314744115\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.450667 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.131417  [    2/  207]\n",
            "loss: 0.133910  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "39.129171293228865\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.435149 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.153722  [    2/  207]\n",
            "loss: 0.455852  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "41.826304379850626\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.453740 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.249949  [    2/  207]\n",
            "loss: 0.711753  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "39.26266320608556\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.411507 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.328811  [    2/  207]\n",
            "loss: 0.062283  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "37.10909291356802\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.439652 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.226883  [    2/  207]\n",
            "loss: 0.373330  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "38.90885553508997\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.447405 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.237705  [    2/  207]\n",
            "loss: 0.787519  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "36.91877420991659\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.482337 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.557813  [    2/  207]\n",
            "loss: 0.426754  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "38.17008739989251\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.470540 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.647402  [    2/  207]\n",
            "loss: 0.952305  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "37.34602924436331\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.470049 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.353702  [    2/  207]\n",
            "loss: 0.362054  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.44503968581557\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.438636 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.224871  [    2/  207]\n",
            "loss: 0.660034  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.86071088351309\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 0.538444 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.191867  [    2/  207]\n",
            "loss: 0.266016  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.48608886357397\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.426873 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.095271  [    2/  207]\n",
            "loss: 0.283056  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "34.46837146393955\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.450482 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.362709  [    2/  207]\n",
            "loss: 0.406530  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.58976395986974\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.390317 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.387728  [    2/  207]\n",
            "loss: 0.181397  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "36.393655941821635\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.413886 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.136436  [    2/  207]\n",
            "loss: 0.060576  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "33.44852738827467\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.399338 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.467752  [    2/  207]\n",
            "loss: 0.294946  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "34.8296909686178\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.399417 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.247497  [    2/  207]\n",
            "loss: 0.263851  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "36.0835925899446\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.390161 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.109021  [    2/  207]\n",
            "loss: 0.179994  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "33.28459911607206\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.394749 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.258936  [    2/  207]\n",
            "loss: 0.119432  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "34.82112038694322\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.395758 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.726414  [    2/  207]\n",
            "loss: 0.255748  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "37.175258996896446\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.470416 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.216236  [    2/  207]\n",
            "loss: 0.475301  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "32.06695699505508\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.380525 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.328711  [    2/  207]\n",
            "loss: 0.387740  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.327540311962366\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.472793 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.359316  [    2/  207]\n",
            "loss: 0.104551  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "34.05643336195499\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.461640 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.128696  [    2/  207]\n",
            "loss: 0.268666  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "34.292122369632125\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.395573 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.090580  [    2/  207]\n",
            "loss: 0.160859  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.311285685747862\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.361261 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.681948  [    2/  207]\n",
            "loss: 0.050856  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "33.04418186750263\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.391040 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.526678  [    2/  207]\n",
            "loss: 0.298016  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "32.64320525340736\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.394493 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.198065  [    2/  207]\n",
            "loss: 0.212729  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.08695776946843\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.440012 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.216641  [    2/  207]\n",
            "loss: 0.667231  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.420783248730004\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.374927 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.570342  [    2/  207]\n",
            "loss: 0.261667  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.27288969885558\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.362401 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.163249  [    2/  207]\n",
            "loss: 0.088153  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.872070150449872\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.394072 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.099358  [    2/  207]\n",
            "loss: 0.041693  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "29.355374082922935\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.465075 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.093173  [    2/  207]\n",
            "loss: 0.290566  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.97165108844638\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.394983 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.108088  [    2/  207]\n",
            "loss: 0.096672  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "35.28914793860167\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.394052 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.982133  [    2/  207]\n",
            "loss: 0.177372  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.91419570846483\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.375780 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.022921  [    2/  207]\n",
            "loss: 0.439384  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.46134663466364\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.426790 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.029276  [    2/  207]\n",
            "loss: 0.685605  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.805702472571284\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.394035 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.002375  [    2/  207]\n",
            "loss: 0.012090  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.487767529673874\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.354261 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.012615  [    2/  207]\n",
            "loss: 0.559808  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "29.635922456160188\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.401736 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.134710  [    2/  207]\n",
            "loss: 0.154810  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.942084982059896\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.350244 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.269540  [    2/  207]\n",
            "loss: 0.081585  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.73204525373876\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.413224 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.148633  [    2/  207]\n",
            "loss: 0.285591  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.101990738417953\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.465038 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 1.594180  [    2/  207]\n",
            "loss: 0.143154  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.22256138897501\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.367328 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.051306  [    2/  207]\n",
            "loss: 0.193906  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "28.877294862642884\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.393812 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.144818  [    2/  207]\n",
            "loss: 0.019463  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.91398270148784\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.387771 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.099219  [    2/  207]\n",
            "loss: 1.003206  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "29.09798062662594\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.395848 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.252290  [    2/  207]\n",
            "loss: 0.079670  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.42226534569636\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.390244 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.474811  [    2/  207]\n",
            "loss: 0.345765  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.954065717756748\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.396507 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.076969  [    2/  207]\n",
            "loss: 0.378200  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "28.349965266883373\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.422494 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.652284  [    2/  207]\n",
            "loss: 0.771813  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "31.045447381213307\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.368357 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.138386  [    2/  207]\n",
            "loss: 0.625718  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.705086418427527\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.363410 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.041949  [    2/  207]\n",
            "loss: 0.159436  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "28.0118228639476\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.369587 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.134970  [    2/  207]\n",
            "loss: 0.096766  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.22269829781726\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.367350 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.670550  [    2/  207]\n",
            "loss: 0.020952  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.19879986392334\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 0.544415 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.038058  [    2/  207]\n",
            "loss: 0.192015  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.76002482511103\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.379886 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.804016  [    2/  207]\n",
            "loss: 0.082460  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.263370086671785\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.384797 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.414437  [    2/  207]\n",
            "loss: 0.107224  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "29.24888905696571\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.452627 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.385265  [    2/  207]\n",
            "loss: 0.091597  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.68270435440354\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.364875 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.351701  [    2/  207]\n",
            "loss: 0.062206  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "27.53428281331435\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.375960 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.152719  [    2/  207]\n",
            "loss: 0.352082  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.665007268544286\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.356161 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.145918  [    2/  207]\n",
            "loss: 0.229586  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.36442327639088\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.342194 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.364361  [    2/  207]\n",
            "loss: 0.312829  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "30.03629042347893\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.461691 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.266857  [    2/  207]\n",
            "loss: 0.057003  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.54185506515205\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.414512 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.017031  [    2/  207]\n",
            "loss: 0.155668  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.65916427760385\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.364258 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.006698  [    2/  207]\n",
            "loss: 0.051420  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.734693817794323\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.416815 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.627863  [    2/  207]\n",
            "loss: 0.049393  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "28.769535613711923\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.417741 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.190188  [    2/  207]\n",
            "loss: 0.152413  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.247334082610905\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.377963 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.007304  [    2/  207]\n",
            "loss: 0.084456  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.126453728415072\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.366581 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 1.092942  [    2/  207]\n",
            "loss: 0.167320  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.930753849446774\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.365099 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.505402  [    2/  207]\n",
            "loss: 0.005137  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "27.779794924077578\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.370415 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.049734  [    2/  207]\n",
            "loss: 0.202260  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "28.220841525588185\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.338087 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.028039  [    2/  207]\n",
            "loss: 0.070953  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.298782844096422\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.328301 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.808344  [    2/  207]\n",
            "loss: 0.352776  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.14195996231865\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.386679 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.526353  [    2/  207]\n",
            "loss: 0.044215  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.814901288598776\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.399705 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.001327  [    2/  207]\n",
            "loss: 0.061494  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.241598076652735\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.310605 \n",
            "\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "loss: 0.625247  [    2/  207]\n",
            "loss: 0.203929  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.941313137765974\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.406844 \n",
            "\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "loss: 0.152091  [    2/  207]\n",
            "loss: 0.284687  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.183841390535235\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.342067 \n",
            "\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "loss: 0.079654  [    2/  207]\n",
            "loss: 0.103487  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.416088410187513\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.370503 \n",
            "\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "loss: 0.194734  [    2/  207]\n",
            "loss: 0.162407  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.353213590104133\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.320970 \n",
            "\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "loss: 0.225123  [    2/  207]\n",
            "loss: 0.080416  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "29.02714765165001\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.435910 \n",
            "\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "loss: 0.321519  [    2/  207]\n",
            "loss: 0.239685  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.39140627393499\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.344525 \n",
            "\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "loss: 0.033756  [    2/  207]\n",
            "loss: 0.071374  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.714334107469767\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.345592 \n",
            "\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "loss: 0.323417  [    2/  207]\n",
            "loss: 0.005204  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.862115523777902\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.361148 \n",
            "\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "loss: 0.146428  [    2/  207]\n",
            "loss: 0.314378  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.743703866028227\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.365953 \n",
            "\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "loss: 0.699978  [    2/  207]\n",
            "loss: 0.116456  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.115335115697235\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.350785 \n",
            "\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "loss: 0.095949  [    2/  207]\n",
            "loss: 0.126583  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.210030005313456\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.323199 \n",
            "\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "loss: 0.005049  [    2/  207]\n",
            "loss: 0.007654  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.58083579968661\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.361269 \n",
            "\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "loss: 0.348628  [    2/  207]\n",
            "loss: 0.084049  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.895157313439995\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.361000 \n",
            "\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "loss: 0.132499  [    2/  207]\n",
            "loss: 0.236603  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.67153116595\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.395159 \n",
            "\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "loss: 0.048925  [    2/  207]\n",
            "loss: 0.142429  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.483334804419428\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.347930 \n",
            "\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "loss: 0.169494  [    2/  207]\n",
            "loss: 0.104843  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "26.03128746256698\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.348803 \n",
            "\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "loss: 0.098024  [    2/  207]\n",
            "loss: 0.050888  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.589288027375005\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.325287 \n",
            "\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "loss: 0.032820  [    2/  207]\n",
            "loss: 0.240700  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.758173801470548\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.344295 \n",
            "\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "loss: 0.134866  [    2/  207]\n",
            "loss: 0.665162  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.26571083930321\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.443494 \n",
            "\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "loss: 0.201012  [    2/  207]\n",
            "loss: 0.082407  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "21.673703981097788\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.343685 \n",
            "\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "loss: 0.315044  [    2/  207]\n",
            "loss: 0.071161  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "21.666108694975264\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.362237 \n",
            "\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "loss: 0.074928  [    2/  207]\n",
            "loss: 0.329733  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "21.780612508300692\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.397726 \n",
            "\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "loss: 0.162687  [    2/  207]\n",
            "loss: 0.018618  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.76891353170504\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.421149 \n",
            "\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "loss: 0.053873  [    2/  207]\n",
            "loss: 1.241458  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "20.01749812765047\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.361787 \n",
            "\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "loss: 0.037742  [    2/  207]\n",
            "loss: 0.216122  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.44075109541882\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.365362 \n",
            "\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "loss: 0.000974  [    2/  207]\n",
            "loss: 0.133301  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.52226505248109\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.372546 \n",
            "\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "loss: 0.379732  [    2/  207]\n",
            "loss: 0.186680  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.025094533746596\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.327834 \n",
            "\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "loss: 0.113783  [    2/  207]\n",
            "loss: 0.209749  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.747166846645996\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.325927 \n",
            "\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "loss: 0.001260  [    2/  207]\n",
            "loss: 0.115525  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.5198275342118\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.507259 \n",
            "\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "loss: 0.031469  [    2/  207]\n",
            "loss: 0.131995  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.723567822016776\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.415138 \n",
            "\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "loss: 0.048795  [    2/  207]\n",
            "loss: 0.120305  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.994949995249044\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.348625 \n",
            "\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "loss: 0.030520  [    2/  207]\n",
            "loss: 0.493592  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "21.964767033816315\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.386671 \n",
            "\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "loss: 0.064378  [    2/  207]\n",
            "loss: 0.376929  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "24.068794921506196\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.350658 \n",
            "\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "loss: 0.362064  [    2/  207]\n",
            "loss: 0.478603  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.444340815069154\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.343661 \n",
            "\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "loss: 0.031880  [    2/  207]\n",
            "loss: 1.325995  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "19.719770902767777\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.417448 \n",
            "\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "loss: 0.000701  [    2/  207]\n",
            "loss: 0.003760  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "25.302230488567147\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.349151 \n",
            "\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "loss: 0.116411  [    2/  207]\n",
            "loss: 0.040803  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "19.785369291435927\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.310277 \n",
            "\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "loss: 0.028157  [    2/  207]\n",
            "loss: 0.002413  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.837675718707033\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.322994 \n",
            "\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "loss: 0.177039  [    2/  207]\n",
            "loss: 0.239692  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.24991494230926\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.342565 \n",
            "\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "loss: 0.369183  [    2/  207]\n",
            "loss: 0.512281  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "20.958284750115126\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.358444 \n",
            "\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "loss: 0.079864  [    2/  207]\n",
            "loss: 0.112602  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "19.759441749949474\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.363894 \n",
            "\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "loss: 0.026562  [    2/  207]\n",
            "loss: 0.054712  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.633803127682768\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.356896 \n",
            "\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "loss: 0.047895  [    2/  207]\n",
            "loss: 0.089868  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.224587387638167\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.328262 \n",
            "\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "loss: 0.156172  [    2/  207]\n",
            "loss: 0.032056  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.493545607547276\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.345637 \n",
            "\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "loss: 0.135118  [    2/  207]\n",
            "loss: 0.024917  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.17439604306128\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.344355 \n",
            "\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "loss: 0.093836  [    2/  207]\n",
            "loss: 0.028233  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "23.682801040587947\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.334118 \n",
            "\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "loss: 0.073260  [    2/  207]\n",
            "loss: 0.233365  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "20.941749956284184\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.339632 \n",
            "\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "loss: 0.116943  [    2/  207]\n",
            "loss: 0.008628  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "19.2612401668448\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.356088 \n",
            "\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "loss: 0.875466  [    2/  207]\n",
            "loss: 0.010395  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "22.129923611646518\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.368478 \n",
            "\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "loss: 1.083413  [    2/  207]\n",
            "loss: 0.030484  [  202/  207]\n",
            "aaaaaaaaaa\n",
            "19.189729720936157\n",
            "104\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.430872 \n",
            "\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td></td></tr><tr><td>Loss/test per epoch</td><td></td></tr><tr><td>Loss/train per epoch</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td>85.71429</td></tr><tr><td>Loss/test per epoch</td><td>0.43087</td></tr><tr><td>Loss/train per epoch</td><td>0.18452</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">magic-night-174</strong> at: <a href='https://wandb.ai/gustavoreis/CatXDogs/runs/oma0b2qe' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs/runs/oma0b2qe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230720_215958-oma0b2qe/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.run(150)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
