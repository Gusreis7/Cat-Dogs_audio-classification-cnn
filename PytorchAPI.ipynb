{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oTMoL4w-f6jk"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.io\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1cYFSNIEQV",
        "outputId": "21ed2c0b-0246-4454-95f1-1022c2f949ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "DEVICE = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "NUM_WORKERS = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE01DalYnP_a"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for x, y in dataset:\n",
        "        xs += [x.to(DEVICE)]\n",
        "        ys += [torch.tensor(y).view(-1,1).to(DEVICE)]\n",
        "    xs = torch.cat(xs)\n",
        "    ys = torch.cat(ys).view(-1,)\n",
        "    return TensorDataset(xs, ys)\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "        image = read_image(img_path,ImageReadMode.RGB).float()\n",
        "       \n",
        "        label = self.img_labels.iloc[idx, 4]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "    \n",
        "class Data:\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test):\n",
        "        self.batch_size = batch_size\n",
        "        self.training_data = load_dataset(dataset_train)\n",
        "        self.test_data = load_dataset(dataset_test)\n",
        "    \n",
        "    def get_loader(self, training: bool):\n",
        "        if training:\n",
        "            dataloader = DataLoader(self.training_data,batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            dataloader = DataLoader(self.test_data,batch_size=self.batch_size, shuffle=False)\n",
        "        return dataloader\n",
        "'''    \n",
        "class Data:\n",
        "    def __init__(self):\n",
        "        root = 'data'\n",
        "        batch_size = 64\n",
        "        self.datasets = {}\n",
        "        self.dataloaders = {}\n",
        "        for is_train in [True, False]:\n",
        "            ds = datasets.FashionMNIST(\n",
        "                root=root,\n",
        "                train=is_train,\n",
        "                download=True,\n",
        "                transform=ToTensor(),\n",
        "            )\n",
        "            self.datasets[is_train] = load_dataset(ds)\n",
        "\n",
        "            self.dataloaders[is_train] = DataLoader(\n",
        "                self.datasets[is_train],\n",
        "                batch_size,\n",
        "                shuffle=is_train,\n",
        "                num_workers=NUM_WORKERS,\n",
        "            )\n",
        "\n",
        "    def get_loader(self, is_train: bool):\n",
        "        return self.dataloaders[is_train]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXVjOIHQn5Dd"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "class Learner:\n",
        "    def __init__(self):\n",
        "        self.model = NeuralNetwork()\n",
        "        self.model.to(DEVICE)\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def update(self, loss):\n",
        "        # Backpropagation\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As9ktj9wogCW"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self):\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_loss(self, y, y_hat):\n",
        "        return self.loss_fn(y_hat, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0vHOBrxpBZS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator):\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "    def one_epoch(self, training: bool):\n",
        "        self.learner.model.train(training)\n",
        "        dataloader = self.data.get_loader(training)\n",
        "        test_loss, correct = 0, 0\n",
        "        num_batches = len(dataloader)\n",
        "        size = len(dataloader.dataset)\n",
        "        for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            #X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = self.learner.predict(X)\n",
        "            loss = self.evaluator.get_loss(y, y_hat)\n",
        "            if training:\n",
        "                self.learner.update(loss)\n",
        "                if batch_idx % 100 == 0:\n",
        "                    loss, current = loss.item(), (batch_idx + 1) * len(X)\n",
        "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            else:\n",
        "                test_loss += loss.item()\n",
        "                correct += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
        "        if not training:\n",
        "            test_loss /= num_batches\n",
        "            correct /= size\n",
        "            print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    def run(self, n_epochs: int):\n",
        "        for t in range(n_epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            #start = time.time()\n",
        "            self.one_epoch(training=True)\n",
        "            #end = time.time()\n",
        "            #print(f\"time: {end - start:.2f}s\")\n",
        "            with torch.no_grad():\n",
        "                self.one_epoch(training=False)\n",
        "        print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbPFwuwbFbue"
      },
      "outputs": [],
      "source": [
        "data = Data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWKYjpcTF9QO",
        "outputId": "b8f395e1-18bf-4cc9-cb6d-239bb7dbbad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "for X, y in data.get_loader(False):\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cDEEBI8GHRR"
      },
      "outputs": [],
      "source": [
        "learner = Learner()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOEE4xAqGPVG"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvYcJxBiGV5R"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(data, learner, evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YljWIIb2Gea6",
        "outputId": "f1bb324b-ba21-4372-a4a7-31f8d615aa61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 66.1%, Avg loss: 0.959632 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 0.889571 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 0.839861 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 69.4%, Avg loss: 0.803905 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 71.7%, Avg loss: 0.773915 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 0.747857 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 73.8%, Avg loss: 0.725759 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 74.7%, Avg loss: 0.706623 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 0.690545 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 76.3%, Avg loss: 0.673279 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 76.7%, Avg loss: 0.659967 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.645352 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 0.632631 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 0.622030 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.612008 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 0.601784 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 79.2%, Avg loss: 0.593428 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 79.4%, Avg loss: 0.585881 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.578125 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.572469 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 0.565087 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 80.6%, Avg loss: 0.559093 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 80.7%, Avg loss: 0.553730 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.548119 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.543133 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "trainer.run(25)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
