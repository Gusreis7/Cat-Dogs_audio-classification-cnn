{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "oTMoL4w-f6jk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch import nn\n",
        "import wandb\n",
        "from PIL import Image\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torchaudio\n",
        "import librosa\n",
        "from torchaudio import transforms\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgustavoreis\u001b[0m (\u001b[33mtropadochatgpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1cYFSNIEQV",
        "outputId": "21ed2c0b-0246-4454-95f1-1022c2f949ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "DEVICE = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "NUM_WORKERS = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rE01DalYnP_a"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomAudioDataset(Dataset):\n",
        "    '''\n",
        "    [EN]Custom dataset class, define the dataset and transformations in the data files\n",
        "    [PT-BR]Classe dataset customizado, define o dataset e as transformações nos arquivos de dados\n",
        "    '''\n",
        "    def __init__(self, annotations_file,path_idx,label_idx, base_dir,target_sample_rate ,transform=None, target_transform=None, labe2id = None):\n",
        "        '''\n",
        "        [EN] \n",
        "        files -> csv file with the metadata of data\n",
        "        path_idx -> index of file path info in the given csv\n",
        "        label_idx -> index of label info in the given csv\n",
        "        base_dir -> base directory to be joined with the given path of files\n",
        "        sample rate -> target sample rate for the audio data\n",
        "        transform -> torch transforms to be aplied in the audio\n",
        "        target transform -> torch transforms to be applied in the label\n",
        "        label2id -> defining id to labels #improve to be automatic\n",
        "        [PT-BR]\n",
        "        files -> arquivo csv com os metadados dos dados\n",
        "        path_idx -> índice das informações do caminho do arquivo no csv fornecido\n",
        "        label_idx -> índice de informações do rótulo no csv fornecido\n",
        "        base_dir -> diretório base a ser associado ao caminho de arquivos fornecido\n",
        "        sample rate -> sample rate alvo para os dados de áudio\n",
        "        transform -> transformações torch a serem aplicadas no áudio\n",
        "        target transform -> transformações torch a serem aplicadas nas labels\n",
        "        label2id -> definindo id para as labels #melhorar para ser automático\n",
        "        '''\n",
        "\n",
        "        self.files = pd.read_csv(annotations_file)\n",
        "        self.path_idx = path_idx\n",
        "        self.label_idx = label_idx\n",
        "        self.base_dir = base_dir\n",
        "        self.sample_rate = target_sample_rate\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.label2id = {'cat':0,'dog':1}\n",
        "\n",
        "    def get_db_spectogram(self,waveform):\n",
        "        '''\n",
        "        [EN]waveform -> wav tensor to convert to spectrogram \n",
        "        [PT-BR] waveform -> tensor wav para converter para espectrogram\n",
        "        '''\n",
        "        transform = torchaudio.transforms.Spectrogram(n_fft=600)\n",
        "        masking = torchaudio.transforms.TimeMasking(time_mask_param=80,p=0.25)\n",
        "        spectrogram = transform(waveform)\n",
        "        spectrogram = transforms.AmplitudeToDB()(spectrogram)\n",
        "        spectrogram = masking(spectrogram)\n",
        "        return spectrogram\n",
        "\n",
        "    def audio_padding(self, waveform,sr, max_s):\n",
        "        '''\n",
        "        [EN]padding wav tensors to be the same length \n",
        "        [PT-BR] aplicando padding nos tensores wav para terem o mesmo tamanho\n",
        "        '''\n",
        "        max_len = max_s*sr\n",
        "        n_rows, wav_len = waveform.shape\n",
        "        if (wav_len/sr) > max_s:\n",
        "            waveform = waveform[:,:max_len] # trucating\n",
        "        else:\n",
        "            #complete the edges of audio with zeros\n",
        "            pad_begin = random.randint(0,(max_len - wav_len))\n",
        "            pad_end = max_len -wav_len- pad_begin\n",
        "            begin_zeros = torch.zeros(n_rows,pad_begin)\n",
        "            end_zeros = torch.zeros(n_rows,pad_end)\n",
        "            waveform = torch.cat((begin_zeros, waveform,end_zeros),1)\n",
        "        \n",
        "        return waveform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = os.path.join(self.base_dir, self.files.iloc[idx, self.path_idx])\n",
        "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
        "        if sample_rate != self.sample_rate:\n",
        "            transform = transforms.Resample(sample_rate, self.sample_rate)\n",
        "            waveform = transform(waveform)\n",
        "\n",
        "        waveform = self.audio_padding(waveform,sample_rate,5)\n",
        "        spec = self.get_db_spectogram(waveform)\n",
        "\n",
        "        label = self.files.iloc[idx, self.label_idx]\n",
        "        label = self.label2id[label]\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return spec, label\n",
        "   \n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "class Data:\n",
        "    '''\n",
        "    [EN]Data class, define the dataloader of a dataset object, with a given batch size\n",
        "    [PT-BR]Classe data, define o dataloader de um objeto dataset, dado um batch size\n",
        "    '''\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test):\n",
        "        self.batch_size = batch_size\n",
        "        self.training_data = dataset_train\n",
        "        self.test_data = dataset_test\n",
        "    \n",
        "    def get_loader(self, training: bool):\n",
        "        if training:\n",
        "            dataloader = DataLoader(self.training_data,batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            dataloader = DataLoader(self.test_data,batch_size=self.batch_size, shuffle=False)\n",
        "        return dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "As9ktj9wogCW"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    '''\n",
        "    [EN] Evaluator class for loss function\n",
        "    [PT-BR] Classe de Evaluator do modelo para função de custo\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_loss(self, y, y_hat):\n",
        "        return self.loss_fn(y_hat, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    '''\n",
        "    [EN]Defining the model architeture\n",
        "    [PT-BR] Definindo a arquitetura do modelo\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(1,128, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128,64, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64,32, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32,16, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        )\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(16*20*18,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.Linear(32, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = self.conv_layer(x)\n",
        "        #print(x.shape)\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "   \n",
        "    \n",
        "class Learner:\n",
        "    '''\n",
        "    [EN]Defining the optimizer of model, Adam is used for faster convergence\n",
        "    [PT-BR]Definindo um otimizadar para o modelo, o Adam é usado para ter uma convergência mais rápida\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.model = NeuralNetwork()\n",
        "        self.model.to(DEVICE)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=2e-6)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def update(self, loss):\n",
        "        # Backpropagation\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0vHOBrxpBZS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator):\n",
        "        '''\n",
        "        [EN]\n",
        "        Data object, that contains the dataset and dataloader\n",
        "        Learner object the model architeture and its optimizer and predict function\n",
        "        Evaluator object with the loss function and update \n",
        "        [PT-BR]\n",
        "        Objeto Data, que contém o dataset e o dataloader\n",
        "        Objeto Learner, a arquitetura do modelo e seu otimizador e função de predict\n",
        "        Objeto Evaluator, contém a função da loss \n",
        "        '''\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "        self.evaluator = evaluator\n",
        "        self.best_acc = 0\n",
        "\n",
        "    def one_epoch(self, training: bool):\n",
        "        self.learner.model.train(training)\n",
        "        dataloader = self.data.get_loader(training)\n",
        "        test_loss, correct = 0, 0\n",
        "        train_loss = 0\n",
        "        num_batches = len(dataloader)\n",
        "        size = len(dataloader.dataset)\n",
        "        for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = self.learner.predict(X)\n",
        "            loss = self.evaluator.get_loss(y, y_hat)\n",
        "            if training:\n",
        "                self.learner.update(loss)\n",
        "                train_loss += loss.item()\n",
        "                if batch_idx % 100 == 0:\n",
        "                    loss, current = loss.item(), (batch_idx + 1) * len(X)\n",
        "                    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "                \n",
        "            else:\n",
        "                test_loss += loss.item()\n",
        "                correct += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "        if not training:\n",
        "            test_loss /= num_batches\n",
        "            correct /= size\n",
        "            test_acc = 100*correct\n",
        "            print(f\"Test Error: \\n Accuracy: {test_acc:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "            return test_loss, test_acc\n",
        "        else:\n",
        "            train_loss /= num_batches\n",
        "            return train_loss\n",
        "\n",
        "    def run(self, n_epochs: int):\n",
        "        wandb.init(project=\"CatXDogs\", entity=\"gustavoreis\")\n",
        "        for t in range(n_epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            #start = time.time()\n",
        "            train_loss = self.one_epoch(training=True)\n",
        "            #end = time.time()\n",
        "            #print(f\"time: {end - start:.2f}s\")\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_acc = self.one_epoch(training=False)\n",
        "            if test_acc > self.best_acc:\n",
        "                torch.save(self.learner.model.state_dict(), 'best-model_parameters.pt')\n",
        "            wandb.log({\"Loss/train per epoch\": train_loss, \"Loss/test per epoch\": test_loss, \"Accuracy/test\": test_acc})\n",
        "        print(\"Done!\")\n",
        "        wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JbPFwuwbFbue"
      },
      "outputs": [],
      "source": [
        "dataset_train = CustomAudioDataset('dataset/train.csv',base_dir ='',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "dataset_test = CustomAudioDataset('dataset/test.csv',base_dir = '',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "data = Data(2, dataset_train,dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6cDEEBI8GHRR"
      },
      "outputs": [],
      "source": [
        "learner = Learner()\n",
        "evaluator = Evaluator()\n",
        "trainer = Trainer(data, learner, evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YljWIIb2Gea6",
        "outputId": "f1bb324b-ba21-4372-a4a7-31f8d615aa61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgustavoreis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gustavo/PersonalProjects/Cat-Dogs_audio-classification/wandb/run-20230722_115249-9c3a8rgl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gustavoreis/CatXDogs/runs/9c3a8rgl' target=\"_blank\">dandy-donkey-215</a></strong> to <a href='https://wandb.ai/gustavoreis/CatXDogs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gustavoreis/CatXDogs' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gustavoreis/CatXDogs/runs/9c3a8rgl' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs/runs/9c3a8rgl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.495740  [    2/  207]\n",
            "loss: 0.504373  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.751338 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.715367  [    2/  207]\n",
            "loss: 0.714323  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.751115 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.505058  [    2/  207]\n",
            "loss: 0.505865  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.750688 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.715166  [    2/  207]\n",
            "loss: 0.714459  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.750294 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.714942  [    2/  207]\n",
            "loss: 0.920271  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.749755 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.507548  [    2/  207]\n",
            "loss: 0.919335  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.749318 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.918744  [    2/  207]\n",
            "loss: 0.917588  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.748826 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.713743  [    2/  207]\n",
            "loss: 0.511267  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.748112 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.713531  [    2/  207]\n",
            "loss: 0.512856  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.747379 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.713189  [    2/  207]\n",
            "loss: 0.909583  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.746557 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.712235  [    2/  207]\n",
            "loss: 0.713544  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.745607 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.711361  [    2/  207]\n",
            "loss: 0.711533  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.744413 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.712165  [    2/  207]\n",
            "loss: 0.897002  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.742805 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.523356  [    2/  207]\n",
            "loss: 0.891247  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.742034 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.893035  [    2/  207]\n",
            "loss: 0.706218  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.739945 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.707805  [    2/  207]\n",
            "loss: 0.878536  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.737559 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.878591  [    2/  207]\n",
            "loss: 0.704764  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.735808 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.872620  [    2/  207]\n",
            "loss: 0.861712  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.733667 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.705651  [    2/  207]\n",
            "loss: 0.851780  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.729531 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.707011  [    2/  207]\n",
            "loss: 0.842646  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.725493 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.566807  [    2/  207]\n",
            "loss: 0.566578  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.723787 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.829380  [    2/  207]\n",
            "loss: 0.697937  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.719363 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.572197  [    2/  207]\n",
            "loss: 0.702726  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.714796 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.688714  [    2/  207]\n",
            "loss: 0.700545  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.710782 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.704733  [    2/  207]\n",
            "loss: 0.597782  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.705874 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.703822  [    2/  207]\n",
            "loss: 0.611610  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.704946 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.695444  [    2/  207]\n",
            "loss: 0.627168  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.699592 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.677418  [    2/  207]\n",
            "loss: 0.691869  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.694925 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.680027  [    2/  207]\n",
            "loss: 0.647179  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.692710 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.727443  [    2/  207]\n",
            "loss: 0.679614  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 60.0%, Avg loss: 0.680817 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.650356  [    2/  207]\n",
            "loss: 0.700434  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 60.0%, Avg loss: 0.679676 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.702232  [    2/  207]\n",
            "loss: 0.673351  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.670386 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.699502  [    2/  207]\n",
            "loss: 0.712617  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.671896 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.684173  [    2/  207]\n",
            "loss: 0.665214  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.666336 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.734517  [    2/  207]\n",
            "loss: 0.635170  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.661056 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.646393  [    2/  207]\n",
            "loss: 0.646306  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.656895 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.690898  [    2/  207]\n",
            "loss: 0.621444  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.645108 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.638218  [    2/  207]\n",
            "loss: 0.625981  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.653217 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.613773  [    2/  207]\n",
            "loss: 0.663295  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.646636 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.657629  [    2/  207]\n",
            "loss: 0.732369  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.639111 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.609132  [    2/  207]\n",
            "loss: 0.589267  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.643722 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.596738  [    2/  207]\n",
            "loss: 0.646187  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.627689 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.678284  [    2/  207]\n",
            "loss: 0.680325  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.624994 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.614289  [    2/  207]\n",
            "loss: 0.675545  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.628229 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.820103  [    2/  207]\n",
            "loss: 0.679801  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.623598 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.774695  [    2/  207]\n",
            "loss: 0.526715  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.617555 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.596031  [    2/  207]\n",
            "loss: 0.639858  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 67.1%, Avg loss: 0.606866 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.576834  [    2/  207]\n",
            "loss: 0.724491  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.612231 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.593645  [    2/  207]\n",
            "loss: 0.498976  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.615431 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.527676  [    2/  207]\n",
            "loss: 0.665983  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.595239 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.790482  [    2/  207]\n",
            "loss: 0.565924  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 0.596839 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.499219  [    2/  207]\n",
            "loss: 0.650887  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.597766 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.530268  [    2/  207]\n",
            "loss: 0.496678  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.596244 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.535298  [    2/  207]\n",
            "loss: 0.463592  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.594831 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.523789  [    2/  207]\n",
            "loss: 0.596579  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 0.589011 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.475324  [    2/  207]\n",
            "loss: 0.865342  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.592431 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.649066  [    2/  207]\n",
            "loss: 0.497656  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.583873 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.857154  [    2/  207]\n",
            "loss: 0.698882  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.581525 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.481349  [    2/  207]\n",
            "loss: 0.543460  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.573982 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.482790  [    2/  207]\n",
            "loss: 0.821933  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.559538 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.679128  [    2/  207]\n",
            "loss: 0.680370  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.561952 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.517886  [    2/  207]\n",
            "loss: 0.505617  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.564099 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.452024  [    2/  207]\n",
            "loss: 0.877497  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.567493 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.600833  [    2/  207]\n",
            "loss: 0.458992  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.563700 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.417192  [    2/  207]\n",
            "loss: 0.419866  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.550985 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.664601  [    2/  207]\n",
            "loss: 0.569743  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.544819 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.380941  [    2/  207]\n",
            "loss: 0.942459  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 0.539759 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.410075  [    2/  207]\n",
            "loss: 0.456372  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.542884 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.471743  [    2/  207]\n",
            "loss: 0.780864  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.547009 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.573232  [    2/  207]\n",
            "loss: 0.444883  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.532067 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.642516  [    2/  207]\n",
            "loss: 0.446326  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.528069 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.367869  [    2/  207]\n",
            "loss: 0.747056  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.488174 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.332957  [    2/  207]\n",
            "loss: 0.444417  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.457006 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.422134  [    2/  207]\n",
            "loss: 0.368811  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.458005 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.396648  [    2/  207]\n",
            "loss: 0.404460  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.451506 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.455990  [    2/  207]\n",
            "loss: 0.383758  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.444432 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.389539  [    2/  207]\n",
            "loss: 0.747926  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.409498 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.181456  [    2/  207]\n",
            "loss: 0.937931  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.426051 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.516285  [    2/  207]\n",
            "loss: 0.420860  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.404075 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.510570  [    2/  207]\n",
            "loss: 0.177534  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.381682 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.322813  [    2/  207]\n",
            "loss: 0.463048  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.379231 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.239010  [    2/  207]\n",
            "loss: 0.368217  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.385559 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.459022  [    2/  207]\n",
            "loss: 0.225760  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.365934 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.128019  [    2/  207]\n",
            "loss: 0.326098  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.356827 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.337953  [    2/  207]\n",
            "loss: 0.539330  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.345405 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.391107  [    2/  207]\n",
            "loss: 0.270132  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.343788 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.395004  [    2/  207]\n",
            "loss: 0.437387  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.328142 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.225174  [    2/  207]\n",
            "loss: 0.308704  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.351465 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.117049  [    2/  207]\n",
            "loss: 0.355310  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.332811 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.376214  [    2/  207]\n",
            "loss: 0.183287  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.328851 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.154165  [    2/  207]\n",
            "loss: 0.081123  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.320426 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.463366  [    2/  207]\n",
            "loss: 0.360755  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.304085 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.421561  [    2/  207]\n",
            "loss: 0.144693  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.304015 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.120904  [    2/  207]\n",
            "loss: 0.190323  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.281432 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.266434  [    2/  207]\n",
            "loss: 0.239765  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.298262 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.401953  [    2/  207]\n",
            "loss: 0.144240  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.280625 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.101698  [    2/  207]\n",
            "loss: 0.377873  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.296467 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.205072  [    2/  207]\n",
            "loss: 0.428834  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.290002 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.676654  [    2/  207]\n",
            "loss: 1.480670  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.272649 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.194304  [    2/  207]\n",
            "loss: 0.195384  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.259973 \n",
            "\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "loss: 0.055647  [    2/  207]\n",
            "loss: 0.309335  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.258325 \n",
            "\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "loss: 0.137060  [    2/  207]\n",
            "loss: 0.279954  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.274970 \n",
            "\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "loss: 0.135929  [    2/  207]\n",
            "loss: 0.103982  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.260931 \n",
            "\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "loss: 0.230430  [    2/  207]\n",
            "loss: 0.159311  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.251030 \n",
            "\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "loss: 0.064977  [    2/  207]\n",
            "loss: 0.135841  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.263198 \n",
            "\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "loss: 0.139606  [    2/  207]\n",
            "loss: 0.055990  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.245121 \n",
            "\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "loss: 0.187056  [    2/  207]\n",
            "loss: 0.006495  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.233223 \n",
            "\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "loss: 0.013348  [    2/  207]\n",
            "loss: 0.104366  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.229160 \n",
            "\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "loss: 0.098383  [    2/  207]\n",
            "loss: 0.080849  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.254146 \n",
            "\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "loss: 0.125527  [    2/  207]\n",
            "loss: 0.132738  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.229500 \n",
            "\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "loss: 0.218553  [    2/  207]\n",
            "loss: 0.175907  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.235438 \n",
            "\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "loss: 0.133266  [    2/  207]\n",
            "loss: 0.213598  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.218013 \n",
            "\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "loss: 0.074193  [    2/  207]\n",
            "loss: 0.084223  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.225233 \n",
            "\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "loss: 0.159476  [    2/  207]\n",
            "loss: 0.164549  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.228737 \n",
            "\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "loss: 0.144833  [    2/  207]\n",
            "loss: 0.325869  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.219060 \n",
            "\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "loss: 0.081126  [    2/  207]\n",
            "loss: 0.075533  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.204897 \n",
            "\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "loss: 0.211511  [    2/  207]\n",
            "loss: 0.263747  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.203310 \n",
            "\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "loss: 1.220159  [    2/  207]\n",
            "loss: 0.005805  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.199016 \n",
            "\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "loss: 0.061898  [    2/  207]\n",
            "loss: 0.181942  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.205600 \n",
            "\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "loss: 0.093559  [    2/  207]\n",
            "loss: 0.074528  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.201360 \n",
            "\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "loss: 0.083913  [    2/  207]\n",
            "loss: 0.069827  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.197276 \n",
            "\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "loss: 0.140581  [    2/  207]\n",
            "loss: 0.110143  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.191884 \n",
            "\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "loss: 0.037665  [    2/  207]\n",
            "loss: 0.088028  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.192731 \n",
            "\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "loss: 0.104382  [    2/  207]\n",
            "loss: 0.075420  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.183837 \n",
            "\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "loss: 0.178643  [    2/  207]\n",
            "loss: 0.120390  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.167191 \n",
            "\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "loss: 0.133365  [    2/  207]\n",
            "loss: 0.198442  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.183994 \n",
            "\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "loss: 0.235436  [    2/  207]\n",
            "loss: 0.146357  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.202627 \n",
            "\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "loss: 0.014379  [    2/  207]\n",
            "loss: 0.212655  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.189432 \n",
            "\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "loss: 0.060863  [    2/  207]\n",
            "loss: 0.024662  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.179298 \n",
            "\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "loss: 0.138901  [    2/  207]\n",
            "loss: 0.883797  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.191383 \n",
            "\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "loss: 0.133481  [    2/  207]\n",
            "loss: 0.290060  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.199516 \n",
            "\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "loss: 0.032768  [    2/  207]\n",
            "loss: 0.056347  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.190321 \n",
            "\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "loss: 0.050107  [    2/  207]\n",
            "loss: 0.225060  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.171155 \n",
            "\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "loss: 0.114075  [    2/  207]\n",
            "loss: 0.100336  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.181126 \n",
            "\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "loss: 0.144394  [    2/  207]\n",
            "loss: 0.122877  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.180681 \n",
            "\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "loss: 0.274164  [    2/  207]\n",
            "loss: 0.153127  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.202077 \n",
            "\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "loss: 0.550749  [    2/  207]\n",
            "loss: 0.032317  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.155337 \n",
            "\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "loss: 0.088068  [    2/  207]\n",
            "loss: 0.021020  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.171607 \n",
            "\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "loss: 0.048818  [    2/  207]\n",
            "loss: 0.079899  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.190221 \n",
            "\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "loss: 0.067961  [    2/  207]\n",
            "loss: 0.036497  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.170905 \n",
            "\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "loss: 0.100935  [    2/  207]\n",
            "loss: 0.077913  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.176431 \n",
            "\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "loss: 0.098193  [    2/  207]\n",
            "loss: 0.074351  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.167624 \n",
            "\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "loss: 0.032165  [    2/  207]\n",
            "loss: 0.227751  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.169391 \n",
            "\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "loss: 0.094433  [    2/  207]\n",
            "loss: 0.078141  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.164077 \n",
            "\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "loss: 0.135950  [    2/  207]\n",
            "loss: 0.021495  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.182174 \n",
            "\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "loss: 0.084637  [    2/  207]\n",
            "loss: 0.198050  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.163395 \n",
            "\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "loss: 0.044214  [    2/  207]\n",
            "loss: 0.377511  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.165379 \n",
            "\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "loss: 0.035640  [    2/  207]\n",
            "loss: 0.082067  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.171044 \n",
            "\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "loss: 0.026872  [    2/  207]\n",
            "loss: 0.065307  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.164911 \n",
            "\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "loss: 0.059918  [    2/  207]\n",
            "loss: 0.061953  [  202/  207]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.155346 \n",
            "\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td>▁▁▁▁▁▁▁▁▆▆▆▅▆▅▆▆▅▆▅▇▇▇▇▇████████████████</td></tr><tr><td>Loss/test per epoch</td><td>███████▇▇▇▇▇▆▆▆▆▆▆▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/train per epoch</td><td>███████▇▇▇▇▇▇▆▆▆▆▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td>95.71429</td></tr><tr><td>Loss/test per epoch</td><td>0.15535</td></tr><tr><td>Loss/train per epoch</td><td>0.15304</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dandy-donkey-215</strong> at: <a href='https://wandb.ai/gustavoreis/CatXDogs/runs/9c3a8rgl' target=\"_blank\">https://wandb.ai/gustavoreis/CatXDogs/runs/9c3a8rgl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230722_115249-9c3a8rgl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.run(150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train = CustomAudioDataset('dataset/train.csv',base_dir ='',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "dataset_test = CustomAudioDataset('dataset/test.csv',base_dir = '',path_idx=0,label_idx=1,target_sample_rate=16000)\n",
        "data = Data(2, dataset_train,dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_network = Learner()\n",
        "model_network.model.load_state_dict(torch.load('best-model_parameters.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "     dataloader = data.get_loader(training=False)\n",
        "     for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = model_network.predict(X)\n",
        "            pred = y_hat.argmax(dim=1).tolist()\n",
        "            labels.extend(y.tolist())\n",
        "            preds.extend(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f91a23f3eb0>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cat','dog'])\n",
        "disp.plot()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
